
### CURRENT EFFORTS IN May 07, 2017

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.svm import SVR     
from sklearn.utils import shuffle

aa0=pd.read_csv('/Volumes/16 DOS/Python/Kaggle Russian House/Selected Best/train.csv',sep=',',header=0)
aa02=pd.read_csv('/Volumes/16 DOS/Python/Kaggle Russian House/Selected Best/macro.csv',sep=',',header=0)

df=pd.merge(aa0, aa02, how='left', on='timestamp')
df.columns.get_loc("price_doc")
df=shuffle(df)

b=[df.ix[:,i].dtype for i in range(0,df.shape[1])]
miss=[df.ix[:,i].isnull().sum()/df.shape[0] for i in range(0,df.shape[1])]
selected=np.where(np.array(miss)<.15)[0]

categoricals=[]
for i in range(0,df.shape[1]):
    if df.ix[:,i].dtype=='object':
        categoricals.append(1)
    else:
        categoricals.append(0)
        
for i in np.where(np.array(categoricals)==1)[0]:
    df.ix[:,i] = pd.Categorical(df.ix[:,i])
    df.ix[:,i] = df.ix[:,i].cat.codes

variaveis=np.where(np.array(categoricals)==0)[0]
good_vars=np.where(np.array([df.ix[:,i].isnull().sum()/df.shape[0] for i in variaveis])<.15)[0]

df = df.drop('ecology', 1)

missing=np.where(np.array([df.ix[:,i].isnull().sum()/df.shape[0] for i in good_vars])>0)[0]

for i in missing:
    print(i,df.ix[:,i].dtype)

for i in range(0,df.shape[1]):
    df.ix[:,i]=df.ix[:,i].fillna(df.ix[:,i].mean())

missing=np.where(np.array([df.ix[:,i].isnull().sum()/df.shape[0] for i in good_vars])>0)[0]

df=df.drop(df.columns[missing], axis=1)

ss=[]
for i in range(0,df.shape[1]):
    ss.append(df.ix[:,i].dtype)

a1=np.where(np.array(ss)=='int8')
a2=np.where(np.array(ss)=='int64')
a3=np.where(np.array(ss)=='float64')
sel=np.unique(np.concatenate((a1,a2,a3),axis=1))

df=df[sel].dropna(how='all',axis=1)

st=[]
for i in range(0,df.shape[1]):
    print(i,np.corrcoef(df.ix[:,i],df['price_doc'])[0][1])
    st.append(np.corrcoef(df.ix[:,i],df['price_doc'])[0][1])

part=np.where(np.array(st)>.28)[0]
for i in part: print(i,st[i])

range0=np.delete(range(0,df.shape[1]),288)

for i in part[0:3]:
    for j in range0:
        df[str('engineer'+str(i)+'x'+str(j))]=df.ix[:,i]*df.ix[:,j]

st2=[]
for i in range(0,df.shape[1]):
    print(i,np.corrcoef(df.ix[:,i],df['price_doc'])[0][1])
    st2.append(np.corrcoef(df.ix[:,i],df['price_doc'])[0][1])

p2=np.where(np.array(st2)>.4)[0]

df24=df.ix[:,p2].dropna()

ad=[]
for i in range(0,df24.shape[1]):
    ad.append(len(np.where(df24.ix[:,i]==0)[0]))
delete2=np.where(np.array(ad)>20)

df24.drop(df24.columns[delete2], axis=1, inplace=True)

X_train0=df24.ix[:,[0,2,3,4,5,6,7,8,9,10]].astype(np.float64)
Y_train0=df24.ix[:,1].astype(np.float64)

thre=7
out1=np.where(Y_train0>thre*np.std(Y_train0))[0]
out=[]
for i in range(0,X_train0.shape[1]):
    out.append(np.where(X_train0.ix[:,i]>thre*np.std(X_train0.ix[:,i]))[0])
out2=np.concatenate(out,axis=0)
delete=np.unique(np.concatenate((out1,out2),axis=0))
len(np.unique(np.concatenate(out,axis=0)))

end=int(Y_train0.shape[0]*.8)

X_train=X_train0.drop(delete)
Y_train=Y_train0.drop(delete)

from sklearn.ensemble import GradientBoostingRegressor

model = GradientBoostingRegressor(loss='ls', \
learning_rate=0.6, n_estimators=100, subsample=0.3, 
min_samples_split=400, min_samples_leaf=400, \
min_weight_fraction_leaf=0.0, max_depth=150,\
 init=None, random_state=None, max_features=X_train.shape[1], alpha=0.9, \
 verbose=1, max_leaf_nodes=20, warm_start=True,)

model.fit(X_train, Y_train)

pred0=model.predict(X_train)

error=np.mean(abs(pred0-Y_train))/len(Y_train)
p1=np.log(pred0+1)
r1=np.log(Y_train+1)
where_are_NaNsp1 = np.isnan(p1)
where_are_NaNsr1 = np.isnan(r1)
p1[where_are_NaNsp1] = 0.003
r1[where_are_NaNsr1] = 0.003

RMSLE=np.sqrt(np.sum((p1-r1)**2)/len(Y_train))

pred02=model.predict(X_test)

error2=np.mean(abs(pred02-Y_test))/len(Y_test)
p12=np.log(pred02+1)
r12=np.log(Y_test+1)
where_are_NaNsp12 = np.isnan(p12)
where_are_NaNsr12 = np.isnan(r12)
p12[where_are_NaNsp12] = 0.003
r12[where_are_NaNsr12] = 0.003

RMSLE2=np.sqrt(np.sum((p1-r1)**2)/len(Y_train))
print('RMSLE train=',RMSLE,'error train=',error)
print('RMSLE test=',RMSLE2,'error test=',error2)

plt.plot(np.sort(pred0))
plt.plot(np.sort(Y_train))
plt.show()

ab2=pd.read_csv('/Volumes/16 DOS/Python/Kaggle Russian House/RussianHouse_test.csv',sep=',',header=0)
aa02=pd.read_csv('/Volumes/16 DOS/Python/Kaggle Russian House/Selected Best/macro.csv',sep=',',header=0)
ab2.shape

df3=pd.merge(ab2, aa02, how='left', on='timestamp')
df=df3

b=[df.ix[:,i].dtype for i in range(0,df.shape[1])]
miss=[df.ix[:,i].isnull().sum()/df.shape[0] for i in range(0,df.shape[1])]
selected=np.where(np.array(miss)<.15)[0]

categoricals=[]
for i in range(0,df.shape[1]):
    if df.ix[:,i].dtype=='object':
        categoricals.append(1)
    else:
        categoricals.append(0)
        
for i in np.where(np.array(categoricals)==1)[0]:
    df.ix[:,i] = pd.Categorical(df.ix[:,i])
    df.ix[:,i] = df.ix[:,i].cat.codes

variaveis=np.where(np.array(categoricals)==0)[0]
good_vars=np.where(np.array([df.ix[:,i].isnull().sum()/df.shape[0] for i in variaveis])<.15)[0]

df = df.drop('ecology', 1)

missing=np.where(np.array([df.ix[:,i].isnull().sum()/df.shape[0] for i in good_vars])>0)[0]

for i in missing:
    print(i,df.ix[:,i].dtype)

for i in range(0,df.shape[1]):
    df.ix[:,i]=df.ix[:,i].fillna(df.ix[:,i].mean())

missing=np.where(np.array([df.ix[:,i].isnull().sum()/df.shape[0] for i in good_vars])>0)[0]

df=df.dropna(how='all',axis=1)

ss=[]
for i in range(0,df.shape[1]):
    ss.append(df.ix[:,i].dtype)

a1=np.where(np.array(ss)=='int8')
a2=np.where(np.array(ss)=='int64')
a3=np.where(np.array(ss)=='float64')
sel=np.unique(np.concatenate((a1,a2,a3),axis=1))

for i in part[0:3]:
    for j in range0:
        df[str('engineer'+str(i)+'x'+str(j))]=df.ix[:,i]*df.ix[:,j]

usar=X_train.columns.values

X_test=df.ix[:,usar]
plt.plot(np.sort(X_test.ix[:,0]))
plt.plot(np.sort(X_test.ix[:,1]))

pred=model.predict(X_test)
id0=df3.ix[:,0]

cc=np.array([np.array(id0),pred]).T

best=pd.read_csv('/Volumes/16 DOS/Python/Kaggle_Rus_12!!!!.csv',sep=',',header=0)

plt.figure(figsize=(10,7))
plt.plot(np.sort(pred))
plt.plot(np.sort(best.ix[:,1]))
plt.title('BLUE PREDICTION')
plt.show()
np.min(pred)

np.savetxt("Melhor_01.csv", cc, delimiter=',', header='id,price_doc', fmt = '%10i, %10f', comments='')
